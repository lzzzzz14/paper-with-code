### Cross-Domain Adaptive Teacher for Object Detection

采用教师-学生模型，学生模型通过教师模型生成的伪标签进行监督学习

为了克服传统方法中由于域差异导致的低质量伪标签问题（如误检）

1. 领域对抗学习——学生模型采用特征级别对抗训练，使源域和目标域的特征分布更加一致，确保学生模型产生域不变的特征
2. 弱-强数据增强——给教师模型输入弱增强的目标域图片，给学生模型输入强增强的目标域图片
3. 互相学习策略——使教学模型能够从学生模型中学习，不受源域偏差的影响



跨域目标检测方法：

1. 对抗学习：利用梯度反转层（GRL）和对抗训练，对齐源域和目标域的特征表示
2. 基于标注级别的适应和课程学习
3. 教师-学生框架



源域： $D_s = \{(X_s,B_s,C_s)\}$ ，图像数量为$N_s$，$B_s$为边界框的标注，$C_s$为对应的类别表情，$X_s$是源域图像

目标域：$D_t=\{X_t\}$，图像数量为$N_t$，$X_t$是目标域图像



### 教师-学生框架训练：

* 初始化
  * 使用源域有标注数据来训练，初始化特征编码器和检测器
* 相互学习阶段
  * 将初始化的检测器复制成两个相同的模型，即教师模型和学生模型
  * 教师模型生成的伪标签来训练学生模型
  * 学生模型通过EMA将学到的知识更新回教师模型

模型学习：

* 学生模型通过标准的梯度更新进行学习
* 教师模型通过对学生模型权重的指数移动平均（EMA）来更新参数



弱增强：随机水平翻转和裁剪

强增强：随机颜色抖动、灰度化、高斯模糊和剪切块



### 损失函数

faster-rcnn的损失函数：

$L_{\text{sup}}(X_s, B_s, C_s) = L_{\text{cls}}^{\text{rpn}}(X_s, B_s, C_s) + L_{\text{reg}}^{\text{rpn}}(X_s, B_s, C_s) + L_{\text{cls}}^{\text{roi}}(X_s, B_s, C_s) + L_{\text{reg}}^{\text{roi}}(X_s, B_s, C_s),$



生成伪标签之后更新学生模型的损失函数：（无监督损失）

$L_{\text{unsup}}(X_t, \hat{C}t) = L{\text{cls}}^{\text{rpn}}(X_t, \hat{C}t) + L{\text{cls}}^{\text{roi}}(X_t, \hat{C}_t),$

其中$ \hat{C}_t $表示教师模型在目标域上生成的伪标签

**注意**：在无监督损失中，不对边界框回归reg计算损失，因为在未标注数据上预测的边界框的置信度分数只能表示每个目标的类别置信度，而不能代表边界框的位置置信度



### 通过EMA从学生模型更新教师模型

从学生模型中临时复制权重，公式为：
$\theta_t \leftarrow \alpha \theta_t + (1 - \alpha) \theta_s,$

其中$ \theta_t $和$ \theta_s $为教师模型和学生模型的网络参数，$\alpha$是EMA的衰减系数



### 对抗学习——对齐两个域之间的分布

学生模型的encoder之后加入了一个域判别器（Discriminator，记为D），目标是区分特征E（X）来自哪个域（源域/目标域）

定义输入样本属于目标域的概率为D(E(X))，属于源域的概率为1-D(E(X))，采用二元交叉熵损失来更新D

给定输入的图像域标签为d，源域图像d=0，目标域推昂d=1，则判别器损失：

$L_{\text{dis}} = -d \log D(E(X)) - (1 - d) \log (1 - D(E(X)))$

为了学习到域不变的特征，所以鼓励Encoder生成让判别器D混淆的特征

则该对抗优化目标函数定义为：

$L_{\text{adv}} = \max_E \min_D L_{\text{dis}}$

为了简化这种“最小-最大优化”，在特征编码器和判别器之间添加一个梯度反转成（GRL），这样Encoder的梯度以相反的方向计算，就只需要最小化目标$L_{dis}$即可

