# Joint Feature Learning and Relation Modeling for Tracking One-Stream Framework (OSTrack)

（2022年发表在ECCV）

## 动机

目前流行的跟踪框架：两流两阶段跟踪框架（分别==提取模板==和==搜索区域==特征，然后进行关系建模）

​	提取的特征缺乏对目标的感知，目标-背景辨别能力有限

### 提出一种新的单流（OSTrack）框架

将特征学习和关系建模统一起来



## 贡献

1. 提出了一个简洁高效的但流的跟踪框架
2. 在Transformer的多头注意力机制中加入了，Early Candidate Elimination模块，从而加快了模型的推理速度
3. 在基准数据集上进行实验，性能优化



## 跟踪pipeline发展

![三种pipeline](https://img-blog.csdnimg.cn/fff4c8af86264ba8981e1c6eee43af56.png)

| 跟踪器 |                             描述                             |
| :----- | :----------------------------------------------------------: |
| a      | 早期的孪生跟踪器(SiamFC、SiamRPN)和鉴别跟踪器(DIMP、ATOM)属于这种类型，首先通过CNN提取模板和搜索区域的特征，然后再通过后续的关系建模网络来融合这些特征用于后续的任务 |
| b      | 近几年为了更好的进行关系建模，提出了Transformer层，这个关系建模模块模型较大，支持双向的信息交互，代表论文有TransT、STARK。双重结构带来了性能的提升，但不可避免的降低了推理速度 |
| c      | 我们首次将特征提取和关系建模无缝地结合成一个统一的pipeline。该方法在模板和搜索区域之间提供了自由的信息流，且计算量较小。它不仅通过相互引导生成面向目标的特征，而且在训练和测试时间上都是有效的 |



## 网络结构

![在这里插入图片描述](https://img-blog.csdnimg.cn/847b356752c94ceea24d3bcd5a8e7428.png)



## 与双流跟踪器比较

1. 框架

   * 以往的双流Transformer融合跟踪器均采用孪生框架，先分别提取模板和搜索区域的特征，只采用Transformer层对提取的特征进行融合

   ​	这些提取的特征是不自适应的，可能会丢失一些判别信息，这是无法弥补的

   * OSTrack在第一阶段直接将线性投影的模板和搜索区域图像拼接起来，将特征提取和关系建模无缝地结合在一起

     通过模板和搜索区域的相互引导，可以提取出面向目标的特征

2. 以往的Transformer融合跟踪器只采用ImageNet预训练骨干网

   OSTrack使用预训练的ViT模型

3. 单流框架为进一步提高模型性能和推理速度提供了识别和丢弃无用背景区域的可能性



## 候选消除模块

$$
h^i_z = Softmax(\frac{q_i \cdot [K_z;K_x]^T}{\sqrt{d}} \cdot V = [w^i_z;w^i_x] \cdot V
$$

令牌$h^i_z$的：

$q_i$：查询向量

$k_z$：模板对应的键矩阵

$k_x$：搜索区域对应的键矩阵

$V$：值矩阵

权重$w^x_i$决定模板部分$h^i_z$与所有搜索区域标记（候选）之间的相似度

$w^x_i$的第j个项（1≤j≤n），n为输入搜索区域令牌数）决定了$h^i_z$与第j个候选项的相似度



